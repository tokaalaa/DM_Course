{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sheet5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPe0IhKHbDZY04VhF66XoEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tokaalaa/DM_Course/blob/main/Sheet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiezgtH9GX7i"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU_i-M6fF9N_"
      },
      "source": [
        "# Import the dependencies\n",
        "import re\n",
        "import numpy\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJGj5tVvGgrR",
        "outputId": "e25f53d8-b110-4fb6-87fd-d8280c0645ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x33lA50UPBHt"
      },
      "source": [
        "# **Q2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hRET7MUpvHA"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PUpCtwGO_zg"
      },
      "source": [
        "def read_pgm(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        buffer = f.read()\n",
        "    try:\n",
        "        header, width, height, maxval = re.search(\n",
        "            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
        "    except AttributeError:\n",
        "        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n",
        "    \n",
        "    return numpy.frombuffer(buffer,\n",
        "                            dtype='u1',\n",
        "                            count=int(width)*int(height),\n",
        "                            offset=len(header)\n",
        "                            ).flatten()\n",
        "Data_Matrix = [] \n",
        "label = []                           \n",
        "for j in range(40):                            \n",
        "  for i in range(10):\n",
        "    image = read_pgm(\"/content/drive/My Drive/DM_sheet5/orl_dataset/s\"+ str(j+1)+ \"/\" + str(i+1) + \".pgm\")\n",
        "    label.append(j+1)\n",
        "    Data_Matrix.append(image)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrQVvy0voOXY",
        "outputId": "4da91e49-f6ca-47fd-dc2b-b67278d8b8d8"
      },
      "source": [
        "Data_Matrix = np.array(Data_Matrix)\n",
        "print(Data_Matrix.shape)\n",
        "label = np.array(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 10304)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVdfF52PsFM3"
      },
      "source": [
        "## Split the Dataset into Training and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxkvpDeEsJy2"
      },
      "source": [
        "def split_data(Data_Matrix, label,way = 1):\n",
        "    if way == 1:\n",
        "      Train_Data, Test_Data = Data_Matrix[::2], Data_Matrix[1::2]\n",
        "      Train_Label, Test_Label = label[::2], label[1::2]\n",
        "    else:\n",
        "      Train_Data, Test_Data, Train_Label, Test_Label = train_test_split(Data_Matrix, label, \n",
        "                                                    train_size=0.7)\n",
        "    return Train_Data, Test_Data, Train_Label, Test_Label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrXgLp-dtZAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34e35a2-59ac-4d24-a25d-904136e4750d"
      },
      "source": [
        "Train_Data, Test_Data, Train_Label, Test_Label = split_data(Data_Matrix, label,way = 1)\n",
        "\n",
        "print(Train_Data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 10304)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jc59V0LSIEi"
      },
      "source": [
        "## Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YwHihk-oVmM"
      },
      "source": [
        "pc = 5/200\n",
        "def Naive_Bayes(Train_Data, NClassSamples = 5):\n",
        "  m,n = Train_Data.shape\n",
        "  Nclasses = int(m / NClassSamples)\n",
        "  Train_Data =Train_Data.reshape(Nclasses, NClassSamples, -1)\n",
        "  mean = numpy.mean(Train_Data, axis=1)\n",
        "  Z = Train_Data - mean.reshape(40,1,-1)\n",
        "  var = np.sum(Z**2, axis=1)/NClassSamples\n",
        "  return mean,var\n",
        "\n",
        "def Testing(Test_Data, mean, var):\n",
        "  yhat = []\n",
        "  for i in range (0, Test_Data.shape[0]):\n",
        "    exponent = np.exp(-1 * (Test_Data[i,:]-mean)**2 / (2 * var))\n",
        "    RBF = (1/((math.pi*2)**0.5)* var**0.5) * exponent\n",
        "    pred = pc * (np.prod(RBF,axis=1)) \n",
        "    yhat.append(np.argmax(pred)+1)\n",
        "  return yhat\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9P8woSujs3-"
      },
      "source": [
        "## c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OStTnAlVWc5x",
        "outputId": "bea1e698-9223-411e-805f-8f1fd2e163f1"
      },
      "source": [
        "mean, var = Naive_Bayes(Train_Data)\n",
        "yhat = Testing(Test_Data, mean, var)\n",
        "accuracy = np.sum(Test_Label == yhat)/Test_Label.shape[0] * 100\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB-dUQ4Tj4wi"
      },
      "source": [
        "## d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpwmRVBLWbJU",
        "outputId": "b61d6a35-6629-4259-e2f7-0e848dfb707a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(Test_Label, yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvOGp4ogkA-a"
      },
      "source": [
        "## e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLj_75jKjMJe",
        "outputId": "6b504641-2bf9-4608-96aa-e084ce09e6df"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=40)\n",
        "pca_Data_Matrix = pca.fit_transform(Data_Matrix)\n",
        "print(pca_Data_Matrix)\n",
        "Train_Data2, Test_Data2, Train_Label2, Test_Label2 = split_data(pca_Data_Matrix, label,way = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8oD3H_FkPu_",
        "outputId": "46a72d90-36e6-4391-86e5-e73478a5f716"
      },
      "source": [
        "mean, var = Naive_Bayes(Train_Data2)\n",
        "yhat = Testing(Test_Data2, mean, var)\n",
        "accuracy = np.sum(Test_Label2 == yhat)/Test_Label.shape[0] * 100\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c3t-LpUkPvE",
        "outputId": "6b08f7c2-2bf0-4afa-bef3-10610798fb50"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(Test_Label2, yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 4, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 4, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 3, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttbH6SBQTrBq"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfbyPMyFTzuD"
      },
      "source": [
        "C1 = np.array([[2,6],\n",
        "               [3,5],\n",
        "               [4,4],\n",
        "               [5,3],\n",
        "               [6,2],\n",
        "               [6,4],\n",
        "               [6,6],\n",
        "               [8,4],\n",
        "               [9,2],\n",
        "               [9,3]])\n",
        "C2 = np.array([[3,3],\n",
        "               [4,3],\n",
        "               [4,5],\n",
        "               [5,5],\n",
        "               [7,3],\n",
        "               [7,4],\n",
        "               [7,5]])\n",
        "C3 = np.array([[7,2],\n",
        "               [10,1],\n",
        "               [10,3],\n",
        "               [10,5],\n",
        "               [11,3],\n",
        "               [11,4],\n",
        "               [12,2],\n",
        "               [13,4.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85yLjJvUWcUg",
        "outputId": "d1ed3d75-9750-40a1-8855-3dabe42fce98"
      },
      "source": [
        "#a\n",
        "n = 25\n",
        "pc1 = C1.shape[0]/n\n",
        "pc2 = C2.shape[0]/n\n",
        "pc3 = C3.shape[0]/n\n",
        "#b\n",
        "mean1 =np.mean(C1,axis=0)\n",
        "print(mean1)\n",
        "mean2 =np.mean(C2,axis=0)\n",
        "print(mean2)\n",
        "mean3 =np.mean(C3,axis=0)\n",
        "print(mean3)\n",
        "Z1 = C1 - mean1\n",
        "Z2 = C2 - mean2\n",
        "Z3 = C3 - mean3\n",
        "cov1 = Z1.T @ Z1 /Z1.shape[0]\n",
        "cov2 = Z2.T @ Z2 /Z2.shape[0]\n",
        "cov3 = Z3.T @ Z3 /Z3.shape[0]\n",
        "print(cov1)\n",
        "print(cov2)\n",
        "print(cov3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.8 3.9]\n",
            "[5.28571429 4.        ]\n",
            "[10.5     3.0625]\n",
            "[[ 5.16 -1.92]\n",
            " [-1.92  1.89]]\n",
            "[[2.48979592 0.28571429]\n",
            " [0.28571429 0.85714286]]\n",
            "[[2.75       0.78125   ]\n",
            " [0.78125    1.65234375]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiO5s9zmcFlk",
        "outputId": "db100fe6-5db4-4f1f-89ec-e0d96c1e6150"
      },
      "source": [
        "#c\n",
        "p1=[6,5]\n",
        "p2=[9,4]\n",
        "p3=[8,5]\n",
        "\n",
        "f1x = (1/((math.pi*2)**0.5)* np.linalg.det(cov1)**0.5) * np.exp(-1 * (p1-mean1).T @ np.linalg.inv(cov1) @ (p1-mean1)/ 2 )\n",
        "f2x = (1/((math.pi*2)**0.5)* np.linalg.det(cov2)**0.5) * np.exp(-1 * (p1-mean2).T @ np.linalg.inv(cov2) @ (p1-mean2)/ 2 ) \n",
        "f3x = (1/((math.pi*2)**0.5)* np.linalg.det(cov3)**0.5) * np.exp(-1 * (p1-mean3).T @ np.linalg.inv(cov3) @ (p1-mean3)/ 2 )\n",
        "c = np.argmax([f1x*pc1, f2x*pc2, f3x*pc3])  \n",
        "print(\"pred1=\",str(c+1))\n",
        "\n",
        "f1x = (1/((math.pi*2)**0.5)* np.linalg.det(cov1)**0.5) * np.exp(-1 * (p2-mean1).T @ np.linalg.inv(cov1) @ (p2-mean1)/ 2 )\n",
        "f2x = (1/((math.pi*2)**0.5)* np.linalg.det(cov2)**0.5) * np.exp(-1 * (p2-mean2).T @ np.linalg.inv(cov2) @ (p2-mean2)/ 2 ) \n",
        "f3x = (1/((math.pi*2)**0.5)* np.linalg.det(cov3)**0.5) * np.exp(-1 * (p2-mean3).T @ np.linalg.inv(cov3) @ (p2-mean3)/ 2 )\n",
        "c = np.argmax([f1x*pc1, f2x*pc2, f3x*pc3]) \n",
        "print(\"pred2=\",str(c+1))\n",
        "\n",
        "f1x = (1/((math.pi*2)**0.5)* np.linalg.det(cov1)**0.5) * np.exp(-1 * (p2-mean1).T @ np.linalg.inv(cov1) @ (p2-mean1)/ 2 )\n",
        "f2x = (1/((math.pi*2)**0.5)* np.linalg.det(cov2)**0.5) * np.exp(-1 * (p2-mean2).T @ np.linalg.inv(cov2) @ (p2-mean2)/ 2 ) \n",
        "f3x = (1/((math.pi*2)**0.5)* np.linalg.det(cov3)**0.5) * np.exp(-1 * (p2-mean3).T @ np.linalg.inv(cov3) @ (p2-mean3)/ 2 )\n",
        "c = np.argmax([f1x*pc1, f2x*pc2, f3x*pc3]) \n",
        "print(\"pred3=\",str(c+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred1= 1\n",
            "pred2= 3\n",
            "pred3= 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN2iILIjckvq",
        "outputId": "e5eaab2a-90d1-41bb-9ba2-05c8622eb682"
      },
      "source": [
        "#d\n",
        "var1 = np.sum(Z1**2, axis=0)/Z1.shape[0]\n",
        "var2 = np.sum(Z2**2, axis=0)/Z2.shape[0]\n",
        "var3 = np.sum(Z3**2, axis=0)/Z3.shape[0]\n",
        "\n",
        "RBF1 = (1/((math.pi*2)**0.5)* var1**0.5) * np.exp(-1 * (p1-mean1)**2 / (2 * var1))\n",
        "pred1 = pc1 * (np.prod(RBF1,axis=0)) \n",
        "RBF2 = (1/((math.pi*2)**0.5)* var2**0.5) * np.exp(-1 * (p1-mean2)**2 / (2 * var2))\n",
        "pred2 = pc2 * (np.prod(RBF2,axis=0)) \n",
        "RBF3 = (1/((math.pi*2)**0.5)* var3**0.5) * np.exp(-1 * (p1-mean3)**2 / (2 * var3))\n",
        "pred3 = pc3 * (np.prod(RBF3,axis=0)) \n",
        "c = np.argmax([pred1, pred2, pred3]) \n",
        "print(\"pred1=\",str(c+1))\n",
        "\n",
        "RBF1 = (1/((math.pi*2)**0.5)* var1**0.5) * np.exp(-1 * (p2-mean1)**2 / (2 * var1))\n",
        "pred1 = pc1 * (np.prod(RBF1,axis=0)) \n",
        "RBF2 = (1/((math.pi*2)**0.5)* var2**0.5) * np.exp(-1 * (p2-mean2)**2 / (2 * var2))\n",
        "pred2 = pc2 * (np.prod(RBF2,axis=0)) \n",
        "RBF3 = (1/((math.pi*2)**0.5)* var3**0.5) * np.exp(-1 * (p2-mean3)**2 / (2 * var3))\n",
        "pred3 = pc3 * (np.prod(RBF3,axis=0)) \n",
        "c = np.argmax([pred1, pred2, pred3]) \n",
        "print(\"pred2=\",str(c+1))\n",
        "\n",
        "RBF1 = (1/((math.pi*2)**0.5)* var1**0.5) * np.exp(-1 * (p2-mean1)**2 / (2 * var1))\n",
        "pred1 = pc1 * (np.prod(RBF1,axis=0)) \n",
        "RBF2 = (1/((math.pi*2)**0.5)* var2**0.5) * np.exp(-1 * (p2-mean2)**2 / (2 * var2))\n",
        "pred2 = pc2 * (np.prod(RBF2,axis=0)) \n",
        "RBF3 = (1/((math.pi*2)**0.5)* var3**0.5) * np.exp(-1 * (p2-mean3)**2 / (2 * var3))\n",
        "pred3 = pc3 * (np.prod(RBF3,axis=0)) \n",
        "c = np.argmax([pred1, pred2, pred3]) \n",
        "print(\"pred3=\",str(c+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred1= 1\n",
            "pred2= 1\n",
            "pred3= 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqcrE8LQ3Y4C"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMeSHiAb3lw4",
        "outputId": "f81e2e1c-3b6b-42db-ca0e-0352f2b12f2b"
      },
      "source": [
        "#e\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "n_trees = [10,30,100,300]\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "for i in range (len(n_trees)):\n",
        "  for j in range (len(criterion)):\n",
        "      clf = RandomForestClassifier(n_estimators=n_trees[i],criterion = criterion[j])\n",
        "      #Train_Data, Test_Data, Train_Label, Test_Label\n",
        "      clf.fit(Train_Data, Train_Label)\n",
        "      yhat = clf.predict(Test_Data)\n",
        "      accuracy = np.sum(Test_Label == yhat)/Test_Label.shape[0] * 100\n",
        "      print(\"for n_trees=\",n_trees[i],\"and criterion=\", criterion[j],\"accuracy =\" , accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for n_trees= 10 and criterion= gini accuracy = 74.5\n",
            "for n_trees= 10 and criterion= entropy accuracy = 82.5\n",
            "for n_trees= 30 and criterion= gini accuracy = 89.5\n",
            "for n_trees= 30 and criterion= entropy accuracy = 90.0\n",
            "for n_trees= 100 and criterion= gini accuracy = 90.5\n",
            "for n_trees= 100 and criterion= entropy accuracy = 96.5\n",
            "for n_trees= 300 and criterion= gini accuracy = 91.5\n",
            "for n_trees= 300 and criterion= entropy accuracy = 97.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9IGcVT67OpD",
        "outputId": "dcfbac2b-29e4-4acf-9e65-0d317ace9308"
      },
      "source": [
        "#f\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=100)\n",
        "pca_Data_Matrix = pca.fit_transform(Data_Matrix)\n",
        "print(pca_Data_Matrix.shape)\n",
        "Train_Data3, Test_Data3, Train_Label3, Test_Label3 = split_data(pca_Data_Matrix, label,way = 1)\n",
        "for i in range (len(n_trees)):\n",
        "  for j in range (len(criterion)):\n",
        "      clf = RandomForestClassifier(n_estimators=n_trees[i],criterion = criterion[j])\n",
        "      #Train_Data, Test_Data, Train_Label, Test_Label\n",
        "      clf.fit(Train_Data3, Train_Label3)\n",
        "      yhat = clf.predict(Test_Data3)\n",
        "      accuracy = np.sum(Test_Label3 == yhat)/Test_Label3.shape[0] * 100\n",
        "      print(\"for n_trees=\",n_trees[i],\"and criterion=\", criterion[j],\"accuracy =\" , accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 100)\n",
            "for n_trees= 10 and criterion= gini accuracy = 63.0\n",
            "for n_trees= 10 and criterion= entropy accuracy = 56.49999999999999\n",
            "for n_trees= 30 and criterion= gini accuracy = 80.5\n",
            "for n_trees= 30 and criterion= entropy accuracy = 80.5\n",
            "for n_trees= 100 and criterion= gini accuracy = 87.0\n",
            "for n_trees= 100 and criterion= entropy accuracy = 90.0\n",
            "for n_trees= 300 and criterion= gini accuracy = 86.0\n",
            "for n_trees= 300 and criterion= entropy accuracy = 93.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRXA3pWTbZur",
        "outputId": "78b414e5-309d-4ad6-9f66-e437b9ffdae3"
      },
      "source": [
        "classes,class_counts = np.unique(label,return_counts=True)\n",
        "classes,class_counts\n",
        "v= 100\n",
        "Dy = Data_Matrix[Data_Matrix[:,0]<=v,:]\n",
        "DN = Data_Matrix[Data_Matrix[:,0]>v,:]\n",
        "print(Dy.shape, DN.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(204, 10304) (196, 10304)\n",
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzjYeu_bwVp8"
      },
      "source": [
        "# **Decision_Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YDAV-s6afB7"
      },
      "source": [
        "def Decision_Tree(D,labels,min_samples,purity_threshold):\n",
        "  n = D.shape[0]\n",
        "  classes,class_counts = np.unique(label,return_counts=True)\n",
        "  purity = np.max(class_counts/n)\n",
        "  if n <= min_samples or purity >= purity_threshold:\n",
        "    c_ = np.argmax(class_counts/n)+1\n",
        "    #create leaf node and label it with class c_\n",
        "    return\n",
        "  j_,split_point_, score_ = 0,0\n",
        "  for j in range(D.shape[1]):\n",
        "    v,score = Evaluate_Numeric_Attribute(D, labels, j)\n",
        "    if score_ < score:\n",
        "      j_ = j\n",
        "      split_point_ = v\n",
        "      score_ = score\n",
        "  \n",
        "  Dy, labely = D[D[:,j_]<=v,:], label[D[:,j_]<=v,:]\n",
        "  DN, labelN = D[D[:,j_]>v,:], label[D[:,j_]>v,:]\n",
        "  Decision_Tree(Dy, labely,min_samples,purity_threshold), Decision_Tree(DN, labelN,min_samples,purity_threshold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT6tVZU8mF3C"
      },
      "source": [
        "def Evaluate_Numeric_Attribute(D, labels,z):\n",
        "  sorted_D = D[numpy.argsort(D[:, z])].copy()\n",
        "  M = []\n",
        "  N = []\n",
        "  ni = np.zeros((40))#num of classes = 40\n",
        "  n = D.shape[0]\n",
        "  for j in range (n-1):\n",
        "    ni[labels[j]-1] = ni[labels[j]-1] + 1\n",
        "    if sorted_D[j,z] != sorted_D[j+1,z]:\n",
        "      v= (sorted_D[j,z] + sorted_D[j+1,z])/2\n",
        "      M.append(v)\n",
        "      Nvi= ni\n",
        "      N.append(Nvi)\n",
        "  ni[labels[n-1]-1] = ni[labels[n-1]-1] + 1  \n",
        "  v_, score_ = 0,0\n",
        "  for v in M: \n",
        "    Dy, labely = D[D[:,z]<=v,:], label[D[:,z]<=v,:]\n",
        "    DN, labelN = D[D[:,z]>v,:], label[D[:,z]>v,:]\n",
        "    score = Gain(D,labels,Dy, labely, DN, labelN)\n",
        "    if score_ < score:\n",
        "      v_ = v\n",
        "      score_ = score\n",
        "\n",
        "return v_,score_\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU8wbIcWwYqw"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "nc = [50,100,150]\n",
        "for i in range (len(nc)):\n",
        "    pca = PCA(n_components=nc[i])\n",
        "    pca_Data_Matrix = pca.fit_transform(Data_Matrix)\n",
        "    print(pca_Data_Matrix)\n",
        "    Train_Data4, Test_Data4, Train_Label4, Test_Label4 = split_data(pca_Data_Matrix, label,way = 1)\n",
        "    Decision_Tree(Train_Data4,Train_Label4,0,1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}